import streamlit as st
import tempfile
import os
import numpy as np
from PIL import Image
import threading
import time

# Intentar importar dependencias con manejo de errores
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError as e:
    st.error(f"Error importando YOLO: {e}")
    YOLO_AVAILABLE = False

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError as e:
    st.error(f"Error importando OpenCV: {e}")
    CV2_AVAILABLE = False

def main():
    # Configuraci√≥n de la p√°gina
    st.set_page_config(
        page_title="YOLO11 Object Detection",
        page_icon="üéØ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # T√≠tulo principal
    st.title("üéØ YOLO11 Detecci√≥n de Objetos en Tiempo Real")
    st.markdown("### Powered by Ultralytics YOLO11")
    
    # Verificar dependencias
    if not YOLO_AVAILABLE:
        st.error("‚ùå YOLO11 no est√° disponible. Verifica que 'ultralytics' est√© instalado.")
        st.info("üí° Instala las dependencias: `pip install ultralytics`")
        return
    
    if not CV2_AVAILABLE:
        st.error("‚ùå OpenCV no est√° disponible. Verifica que 'opencv-python-headless' est√© instalado.")
        st.info("üí° Instala las dependencias: `pip install opencv-python-headless`")
        return
    
    # Sidebar con configuraci√≥n
    st.sidebar.header("‚öôÔ∏è Configuraci√≥n")
    
    # Selecci√≥n del modelo
    model_options = {
        "YOLO11n (Nano - M√°s r√°pido)": "yolo11n.pt",
        "YOLO11s (Small)": "yolo11s.pt", 
        "YOLO11m (Medium)": "yolo11m.pt",
        "YOLO11l (Large)": "yolo11l.pt",
        "YOLO11x (Extra Large - M√°s preciso)": "yolo11x.pt"
    }
    
    selected_model_name = st.sidebar.selectbox(
        "üîß Seleccionar Modelo YOLO11",
        options=list(model_options.keys()),
        index=0,
        help="Nano es el m√°s r√°pido, Extra Large es el m√°s preciso"
    )
    
    selected_model = model_options[selected_model_name]
    
    # Configuraci√≥n de confianza
    confidence = st.sidebar.slider(
        "üéØ Umbral de Confianza",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="Puntuaci√≥n m√≠nima para considerar una detecci√≥n v√°lida"
    )
    
    # Configuraci√≥n de IoU
    iou = st.sidebar.slider(
        "üìä Umbral IoU",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.05,
        help="Umbral de Intersecci√≥n sobre Uni√≥n para filtrar detecciones superpuestas"
    )
    
    # Tipo de entrada
    st.sidebar.header("üìπ Fuente de Entrada")
    input_type = st.sidebar.radio(
        "Seleccionar fuente:",
        ["C√°mara Web", "Captura de Imagen", "Archivo de Video", "Imagen"],
        help="Elige entre usar tu c√°mara web, capturar una imagen, subir un archivo o una imagen"
    )
    
    # Informaci√≥n del modelo seleccionado
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"**Modelo actual:** {selected_model_name}")
    st.sidebar.markdown(f"**Confianza:** {confidence}")
    st.sidebar.markdown(f"**IoU:** {iou}")
    
    # Inicializar estado de sesi√≥n
    if 'model' not in st.session_state:
        st.session_state.model = None
    if 'model_name' not in st.session_state:
        st.session_state.model_name = None
    if 'stop_camera' not in st.session_state:
        st.session_state.stop_camera = False
    
    # Cargar modelo si es necesario
    if st.session_state.model is None or st.session_state.model_name != selected_model:
        with st.spinner(f"Cargando modelo {selected_model_name}..."):
            try:
                st.session_state.model = YOLO(selected_model)
                # Forzar uso de CPU para evitar problemas de CUDA
                st.session_state.model.to('cpu')
                st.session_state.model_name = selected_model
                st.success(f"‚úÖ Modelo {selected_model_name} cargado exitosamente (CPU)")
            except Exception as e:
                st.error(f"‚ùå Error cargando modelo: {str(e)}")
                st.session_state.model = None
    
    # √Årea principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üöÄ Detecci√≥n de Objetos")
        
        if input_type == "Imagen":
            handle_image_input(confidence, iou)
        elif input_type == "Archivo de Video":
            handle_video_input(confidence, iou)
        elif input_type == "Captura de Imagen":
            handle_camera_capture(confidence, iou)
        else:  # C√°mara Web
            handle_webcam_input(confidence, iou)
    
    with col2:
        st.header("‚ÑπÔ∏è Informaci√≥n")
        
        st.markdown("""
        **üéØ Modelos Disponibles:**
        - **Nano**: M√°s r√°pido, menor precisi√≥n
        - **Small**: Equilibrio velocidad-precisi√≥n
        - **Medium**: Buena precisi√≥n general
        - **Large**: Alta precisi√≥n
        - **Extra Large**: M√°xima precisi√≥n
        
        **‚öôÔ∏è Par√°metros:**
        - **Confianza**: Umbral m√≠nimo para detecciones
        - **IoU**: Filtro para detecciones superpuestas
        
        **üìã Clases Detectadas:**
        YOLO11 puede detectar 80 clases diferentes incluyendo:
        - Personas, animales
        - Veh√≠culos (autos, motos, etc.)
        - Objetos cotidianos
        - Y muchos m√°s...
        """)
        
        st.markdown("---")
        st.markdown("**üîß Instrucciones:**")
        st.markdown("""
        1. Selecciona el modelo YOLO11
        2. Ajusta la confianza e IoU
        3. Elige la fuente de entrada
        4. Haz clic en el bot√≥n correspondiente
        """)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center'>
        <p>üöÄ Powered by <strong>Ultralytics YOLO11</strong> | 
        üìö Built with <strong>Streamlit</strong></p>
    </div>
    """, unsafe_allow_html=True)

def handle_image_input(confidence, iou):
    """Manejar entrada de imagen"""
    st.subheader("üì∏ Detecci√≥n en Imagen")
    
    uploaded_file = st.file_uploader(
        "Seleccionar imagen",
        type=['png', 'jpg', 'jpeg'],
        help="Sube una imagen para detecci√≥n de objetos"
    )
    
    if uploaded_file is not None:
        if st.session_state.model is None:
            st.warning("‚ö†Ô∏è Por favor, espera a que se cargue el modelo")
            return
        
        # Mostrar imagen original
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Original")
            image = Image.open(uploaded_file)
            st.image(image, use_container_width=True)
        
        with col2:
            st.subheader("Detecciones")
            
            if st.button("üîç Detectar Objetos", type="primary"):
                with st.spinner("Procesando imagen..."):
                    try:
                        # Ejecutar inferencia
                        results = st.session_state.model(image, conf=confidence, iou=iou, device='cpu')
                        
                        # Mostrar imagen con detecciones
                        annotated_image = results[0].plot()
                        annotated_pil = Image.fromarray(annotated_image)
                        st.image(annotated_pil, use_container_width=True)
                        
                        # Mostrar resultados
                        if len(results[0].boxes) > 0:
                            st.success(f"‚úÖ Detectados {len(results[0].boxes)} objetos")
                            
                            # Detalles de detecci√≥n
                            with st.expander("Detalles de Detecci√≥n"):
                                for i, box in enumerate(results[0].boxes):
                                    class_id = int(box.cls[0])
                                    conf = float(box.conf[0])
                                    class_name = results[0].names[class_id]
                                    st.write(f"**{i+1}.** {class_name} - Confianza: {conf:.2f}")
                        else:
                            st.info("No se detectaron objetos")
                            
                    except Exception as e:
                        st.error(f"‚ùå Error procesando imagen: {str(e)}")

def handle_video_input(confidence, iou):
    """Manejar entrada de video"""
    st.subheader("üìπ Detecci√≥n en Video")
    
    uploaded_file = st.file_uploader(
        "Seleccionar archivo de video",
        type=['mp4', 'avi', 'mov', 'mkv', 'wmv'],
        help="Sube un archivo de video para detecci√≥n de objetos"
    )
    
    if uploaded_file is not None:
        if st.session_state.model is None:
            st.warning("‚ö†Ô∏è Por favor, espera a que se cargue el modelo")
            return
        
        # Guardar archivo temporalmente
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            temp_path = tmp_file.name
        
        st.success(f"‚úÖ Archivo subido: {uploaded_file.name}")
        
        if st.button("üé¨ Procesar Video", type="primary"):
            with st.spinner("Procesando video..."):
                try:
                    # Ejecutar inferencia en video
                    results = st.session_state.model(temp_path, conf=confidence, iou=iou, save=True, device='cpu')
                    
                    st.success("‚úÖ ¬°Video procesado exitosamente!")
                    st.info("üé• El video con detecciones se ha guardado en la carpeta 'runs'")
                    
                except Exception as e:
                    st.error(f"‚ùå Error al procesar el video: {str(e)}")
                finally:
                    # Limpiar archivo temporal
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)

def init_camera():
    """Inicializar la c√°mara con m√∫ltiples m√©todos"""
    try:
        # M√©todo 1: √çndice 0 (c√°mara principal)
        cap = cv2.VideoCapture(0)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret and frame is not None:
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                return cap, "‚úÖ C√°mara principal inicializada"
            cap.release()
        
        # M√©todo 2: Probar otros √≠ndices
        for i in range(1, 4):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                    return cap, f"‚úÖ C√°mara {i} inicializada"
                cap.release()
        
        # M√©todo 3: Probar con diferentes backends
        backends = [cv2.CAP_DSHOW, cv2.CAP_V4L2, cv2.CAP_GSTREAMER]
        for backend in backends:
            try:
                cap = cv2.VideoCapture(0, backend)
                if cap.isOpened():
                    ret, frame = cap.read()
                    if ret and frame is not None:
                        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                        return cap, f"‚úÖ C√°mara inicializada con backend {backend}"
                    cap.release()
            except:
                continue
        
        return None, "‚ùå No se encontr√≥ ninguna c√°mara disponible"
    except Exception as e:
        return None, f"‚ùå Error al inicializar la c√°mara: {str(e)}"

def handle_camera_capture(confidence, iou):
    """Capturar imagen desde la c√°mara web usando Streamlit"""
    st.subheader("üì∏ Captura de Imagen desde C√°mara")
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Por favor, espera a que se cargue el modelo")
        return
    
    st.info("""
    üì∑ **Captura de imagen desde c√°mara web:**
    - Esta funci√≥n usa la c√°mara web del navegador
    - Funciona mejor que el streaming de video
    - Compatible con Streamlit Cloud
    """)
    
    # Usar st.camera_input para capturar imagen
    camera_image = st.camera_input("Toma una foto para detectar objetos")
    
    if camera_image is not None:
        # Convertir la imagen capturada
        image = Image.open(camera_image)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Imagen Original")
            st.image(image, use_container_width=True)
        
        with col2:
            st.subheader("Detecciones")
            
            if st.button("üîç Detectar Objetos", type="primary", key="detect_camera"):
                with st.spinner("Procesando imagen capturada..."):
                    try:
                        # Ejecutar inferencia
                        results = st.session_state.model(image, conf=confidence, iou=iou, device='cpu')
                        
                        # Mostrar imagen con detecciones
                        annotated_image = results[0].plot()
                        annotated_pil = Image.fromarray(annotated_image)
                        st.image(annotated_pil, use_container_width=True)
                        
                        # Mostrar resultados
                        if len(results[0].boxes) > 0:
                            st.success(f"‚úÖ Detectados {len(results[0].boxes)} objetos")
                            
                            # Detalles de detecci√≥n
                            with st.expander("Detalles de Detecci√≥n"):
                                for i, box in enumerate(results[0].boxes):
                                    class_id = int(box.cls[0])
                                    conf = float(box.conf[0])
                                    class_name = results[0].names[class_id]
                                    st.write(f"**{i+1}.** {class_name} - Confianza: {conf:.2f}")
                        else:
                            st.info("No se detectaron objetos")
                            
                    except Exception as e:
                        st.error(f"‚ùå Error procesando imagen: {str(e)}")

def handle_webcam_input(confidence, iou):
    """Manejar entrada de c√°mara web en tiempo real"""
    st.subheader("üì∑ Detecci√≥n en C√°mara Web - Tiempo Real")
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Por favor, espera a que se cargue el modelo")
        return
    
    # Informaci√≥n sobre la funcionalidad
    st.info("""
    üé• **Detecci√≥n en tiempo real:**
    - Usa la c√°mara web del navegador (igual que Captura de Imagen)
    - Procesa frames continuamente para detecci√≥n en vivo
    - Compatible con Streamlit Cloud y navegadores locales
    - Presiona "Iniciar" para comenzar el streaming
    """)
    
    # Inicializar estados de sesi√≥n
    if 'camera_active' not in st.session_state:
        st.session_state.camera_active = False
    if 'frame_count' not in st.session_state:
        st.session_state.frame_count = 0
    
    # Botones de control
    col1, col2 = st.columns(2)
    
    with col1:
        if not st.session_state.camera_active:
            start_button = st.button("üöÄ Iniciar C√°mara en Vivo", type="primary")
        else:
            start_button = False
    
    with col2:
        if st.session_state.camera_active:
            stop_button = st.button("‚èπÔ∏è Detener C√°mara", type="secondary")
        else:
            stop_button = False
    
    if stop_button:
        st.session_state.camera_active = False
        st.session_state.frame_count = 0
        st.success("üì∑ C√°mara detenida")
        st.rerun()
    
    if start_button:
        st.session_state.camera_active = True
        st.session_state.frame_count = 0
        st.rerun()
    
    # Si la c√°mara est√° activa, mostrar interfaz de streaming
    if st.session_state.camera_active:
        st.markdown("---")
        st.subheader("üìπ Streaming en Vivo")
        
        # Crear placeholder para el video
        video_placeholder = st.empty()
        stats_placeholder = st.empty()
        
        # Usar st.camera_input con key √∫nica para cada frame
        camera_key = f"live_camera_{st.session_state.frame_count}"
        
        with video_placeholder.container():
            # Usar la misma funcionalidad que funciona en "Captura de Imagen"
            camera_image = st.camera_input(
                "üì∏ C√°mara en vivo - Presiona el bot√≥n de captura para procesar",
                key=camera_key,
                help="La imagen se procesar√° autom√°ticamente cuando captures"
            )
            
            if camera_image is not None:
                # Procesar la imagen capturada
                image = Image.open(camera_image)
                
                # Ejecutar inferencia
                with st.spinner("Procesando frame..."):
                    try:
                        results = st.session_state.model(image, conf=confidence, iou=iou, device='cpu')
                        
                        # Mostrar imagen con detecciones
                        annotated_image = results[0].plot()
                        annotated_pil = Image.fromarray(annotated_image)
                        
                        # Mostrar resultado
                        st.image(annotated_pil, use_container_width=True)
                        
                        # Mostrar estad√≠sticas
                        detections = len(results[0].boxes)
                        st.session_state.frame_count += 1
                        
                        with stats_placeholder.container():
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Frames procesados", st.session_state.frame_count)
                            with col2:
                                st.metric("Detecciones", detections)
                            with col3:
                                st.metric("Confianza", f"{confidence:.2f}")
                        
                        # Mostrar detecciones encontradas
                        if detections > 0:
                            st.success(f"‚úÖ {detections} objetos detectados")
                            
                            # Detalles de detecci√≥n en un expander
                            with st.expander("üìã Detalles de Detecci√≥n"):
                                for i, box in enumerate(results[0].boxes):
                                    class_id = int(box.cls[0])
                                    conf = float(box.conf[0])
                                    class_name = results[0].names[class_id]
                                    st.write(f"**{i+1}.** {class_name} - Confianza: {conf:.2f}")
                        else:
                            st.info("No se detectaron objetos en este frame")
                        
                        # Auto-refresh para continuar el streaming
                        if st.session_state.camera_active:
                            time.sleep(0.1)  # Peque√±a pausa para evitar sobrecarga
                            st.rerun()
                            
                    except Exception as e:
                        st.error(f"‚ùå Error procesando frame: {str(e)}")
        
        # Instrucciones para el usuario
        st.markdown("---")
        st.info("""
        üí° **Instrucciones:**
        - Presiona el bot√≥n de captura en la c√°mara para procesar cada frame
        - Los resultados se mostrar√°n autom√°ticamente
        - Presiona "Detener C√°mara" para finalizar
        """)
    
    else:
        # Mostrar informaci√≥n cuando la c√°mara no est√° activa
        st.markdown("---")
        st.markdown("""
        ### üéØ Funcionalidades disponibles:
        
        **üìπ C√°mara Web (Tiempo Real):**
        - Streaming continuo con detecci√≥n frame por frame
        - Usa la c√°mara web del navegador
        - Compatible con Streamlit Cloud
        
        **üì∏ Captura de Imagen:**
        - Captura una sola imagen para an√°lisis
        - Perfecto para an√°lisis detallado
        - Misma tecnolog√≠a de c√°mara
        
        **üí° Recomendaci√≥n:** Si tienes problemas con el streaming, usa "Captura de Imagen" para an√°lisis individual.
        """)

if __name__ == "__main__":
    main()
