import streamlit as st
from ultralytics import YOLO
import tempfile
import os
import cv2
import numpy as np
from PIL import Image
import threading
import time

def main():
    # Configuraci√≥n de la p√°gina
    st.set_page_config(
        page_title="YOLO11 Object Detection",
        page_icon="üéØ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # T√≠tulo principal
    st.title("üéØ YOLO11 Detecci√≥n de Objetos en Tiempo Real")
    st.markdown("### Powered by Ultralytics YOLO11")
    
    # Sidebar con configuraci√≥n
    st.sidebar.header("‚öôÔ∏è Configuraci√≥n")
    
    # Selecci√≥n del modelo
    model_options = {
        "YOLO11n (Nano - M√°s r√°pido)": "yolo11n.pt",
        "YOLO11s (Small)": "yolo11s.pt", 
        "YOLO11m (Medium)": "yolo11m.pt",
        "YOLO11l (Large)": "yolo11l.pt",
        "YOLO11x (Extra Large - M√°s preciso)": "yolo11x.pt"
    }
    
    selected_model_name = st.sidebar.selectbox(
        "üîß Seleccionar Modelo YOLO11",
        options=list(model_options.keys()),
        index=0,
        help="Nano es el m√°s r√°pido, Extra Large es el m√°s preciso"
    )
    
    selected_model = model_options[selected_model_name]
    
    # Configuraci√≥n de confianza
    confidence = st.sidebar.slider(
        "üéØ Umbral de Confianza",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="Puntuaci√≥n m√≠nima para considerar una detecci√≥n v√°lida"
    )
    
    # Configuraci√≥n de IoU
    iou = st.sidebar.slider(
        "üìä Umbral IoU",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.05,
        help="Umbral de Intersecci√≥n sobre Uni√≥n para filtrar detecciones superpuestas"
    )
    
    # Tipo de entrada
    st.sidebar.header("üìπ Fuente de Entrada")
    input_type = st.sidebar.radio(
        "Seleccionar fuente:",
        ["C√°mara Web", "Archivo de Video", "Imagen"],
        help="Elige entre usar tu c√°mara web, subir un archivo o una imagen"
    )
    
    # Informaci√≥n del modelo seleccionado
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"**Modelo actual:** {selected_model_name}")
    st.sidebar.markdown(f"**Confianza:** {confidence}")
    st.sidebar.markdown(f"**IoU:** {iou}")
    
    # Inicializar estado de sesi√≥n
    if 'model' not in st.session_state:
        st.session_state.model = None
    if 'model_name' not in st.session_state:
        st.session_state.model_name = None
    if 'stop_camera' not in st.session_state:
        st.session_state.stop_camera = False
    
    # Cargar modelo si es necesario
    if st.session_state.model is None or st.session_state.model_name != selected_model:
        with st.spinner(f"Cargando modelo {selected_model_name}..."):
            try:
                st.session_state.model = YOLO(selected_model)
                # Forzar uso de CPU para evitar problemas de CUDA
                st.session_state.model.to('cpu')
                st.session_state.model_name = selected_model
                st.success(f"‚úÖ Modelo {selected_model_name} cargado exitosamente (CPU)")
            except Exception as e:
                st.error(f"‚ùå Error cargando modelo: {str(e)}")
                st.session_state.model = None
    
    # √Årea principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üöÄ Detecci√≥n de Objetos")
        
        if input_type == "Imagen":
            handle_image_input(confidence, iou)
        elif input_type == "Archivo de Video":
            handle_video_input(confidence, iou)
        else:  # C√°mara Web
            handle_webcam_input(confidence, iou)
    
    with col2:
        st.header("‚ÑπÔ∏è Informaci√≥n")
        
        st.markdown("""
        **üéØ Modelos Disponibles:**
        - **Nano**: M√°s r√°pido, menor precisi√≥n
        - **Small**: Equilibrio velocidad-precisi√≥n
        - **Medium**: Buena precisi√≥n general
        - **Large**: Alta precisi√≥n
        - **Extra Large**: M√°xima precisi√≥n
        
        **‚öôÔ∏è Par√°metros:**
        - **Confianza**: Umbral m√≠nimo para detecciones
        - **IoU**: Filtro para detecciones superpuestas
        
        **üìã Clases Detectadas:**
        YOLO11 puede detectar 80 clases diferentes incluyendo:
        - Personas, animales
        - Veh√≠culos (autos, motos, etc.)
        - Objetos cotidianos
        - Y muchos m√°s...
        """)
        
        st.markdown("---")
        st.markdown("**üîß Instrucciones:**")
        st.markdown("""
        1. Selecciona el modelo YOLO11
        2. Ajusta la confianza e IoU
        3. Elige la fuente de entrada
        4. Haz clic en el bot√≥n correspondiente
        """)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center'>
        <p>üöÄ Powered by <strong>Ultralytics YOLO11</strong> | 
        üìö Built with <strong>Streamlit</strong></p>
    </div>
    """, unsafe_allow_html=True)

def handle_image_input(confidence, iou):
    """Manejar entrada de imagen"""
    st.subheader("üì∏ Detecci√≥n en Imagen")
    
    uploaded_file = st.file_uploader(
        "Seleccionar imagen",
        type=['png', 'jpg', 'jpeg'],
        help="Sube una imagen para detecci√≥n de objetos"
    )
    
    if uploaded_file is not None:
        if st.session_state.model is None:
            st.warning("‚ö†Ô∏è Por favor, espera a que se cargue el modelo")
            return
        
        # Mostrar imagen original
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Original")
            image = Image.open(uploaded_file)
            st.image(image, use_container_width=True)
        
        with col2:
            st.subheader("Detecciones")
            
            if st.button("üîç Detectar Objetos", type="primary"):
                with st.spinner("Procesando imagen..."):
                    try:
                        # Ejecutar inferencia
                        results = st.session_state.model(image, conf=confidence, iou=iou, device='cpu')
                        
                        # Mostrar imagen con detecciones
                        annotated_image = results[0].plot()
                        annotated_pil = Image.fromarray(annotated_image)
                        st.image(annotated_pil, use_container_width=True)
                        
                        # Mostrar resultados
                        if len(results[0].boxes) > 0:
                            st.success(f"‚úÖ Detectados {len(results[0].boxes)} objetos")
                            
                            # Detalles de detecci√≥n
                            with st.expander("Detalles de Detecci√≥n"):
                                for i, box in enumerate(results[0].boxes):
                                    class_id = int(box.cls[0])
                                    conf = float(box.conf[0])
                                    class_name = results[0].names[class_id]
                                    st.write(f"**{i+1}.** {class_name} - Confianza: {conf:.2f}")
                        else:
                            st.info("No se detectaron objetos")
                            
                    except Exception as e:
                        st.error(f"‚ùå Error procesando imagen: {str(e)}")

def handle_video_input(confidence, iou):
    """Manejar entrada de video"""
    st.subheader("üìπ Detecci√≥n en Video")
    
    uploaded_file = st.file_uploader(
        "Seleccionar archivo de video",
        type=['mp4', 'avi', 'mov', 'mkv', 'wmv'],
        help="Sube un archivo de video para detecci√≥n de objetos"
    )
    
    if uploaded_file is not None:
        if st.session_state.model is None:
            st.warning("‚ö†Ô∏è Por favor, espera a que se cargue el modelo")
            return
        
        # Guardar archivo temporalmente
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            temp_path = tmp_file.name
        
        st.success(f"‚úÖ Archivo subido: {uploaded_file.name}")
        
        if st.button("üé¨ Procesar Video", type="primary"):
            with st.spinner("Procesando video..."):
                try:
                    # Ejecutar inferencia en video
                    results = st.session_state.model(temp_path, conf=confidence, iou=iou, save=True, device='cpu')
                    
                    st.success("‚úÖ ¬°Video procesado exitosamente!")
                    st.info("üé• El video con detecciones se ha guardado en la carpeta 'runs'")
                    
                except Exception as e:
                    st.error(f"‚ùå Error al procesar el video: {str(e)}")
                finally:
                    # Limpiar archivo temporal
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)

def handle_webcam_input(confidence, iou):
    """Manejar entrada de c√°mara web"""
    st.subheader("üì∑ Detecci√≥n en C√°mara Web")
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Por favor, espera a que se cargue el modelo")
        return
    
    # Botones de control
    col1, col2 = st.columns(2)
    
    with col1:
        start_button = st.button("üöÄ Iniciar C√°mara", type="primary")
    
    with col2:
        stop_button = st.button("‚èπÔ∏è Detener C√°mara", type="secondary")
    
    if stop_button:
        st.session_state.stop_camera = True
        st.info("üì∑ C√°mara detenida")
    
    if start_button:
        st.session_state.stop_camera = False
        
        # Placeholders para mostrar video
        frame_placeholder = st.empty()
        info_placeholder = st.empty()
        
        try:
            # Abrir c√°mara
            cap = cv2.VideoCapture(0)
            
            if not cap.isOpened():
                st.error("‚ùå No se pudo abrir la c√°mara")
                return
            
            frame_count = 0
            
            while not st.session_state.stop_camera:
                ret, frame = cap.read()
                
                if not ret:
                    st.error("‚ùå No se pudo leer de la c√°mara")
                    break
                
                frame_count += 1
                
                # Procesar cada 3 frames para mejor rendimiento
                if frame_count % 3 == 0:
                    # Ejecutar inferencia
                    results = st.session_state.model(frame, conf=confidence, iou=iou, device='cpu')
                    
                    # Anotar frame
                    annotated_frame = results[0].plot()
                    
                    # Convertir BGR a RGB para Streamlit
                    annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                    
                    # Mostrar frame
                    frame_placeholder.image(annotated_frame_rgb, channels="RGB", use_container_width=True)
                    
                    # Mostrar informaci√≥n
                    num_detections = len(results[0].boxes) if results[0].boxes is not None else 0
                    info_placeholder.info(f"üìä Detecciones: {num_detections} | Frame: {frame_count}")
                
                # Peque√±a pausa para control de FPS
                time.sleep(0.03)
            
            cap.release()
            
        except Exception as e:
            st.error(f"‚ùå Error con la c√°mara: {str(e)}")
            st.info("üí° Aseg√∫rate de que tu c√°mara est√© conectada y no est√© siendo usada por otra aplicaci√≥n")

if __name__ == "__main__":
    main()
